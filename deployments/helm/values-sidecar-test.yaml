# Sidecar test values - validates nvml-provider sidecar architecture
# Usage: helm upgrade nvsentinel deployments/helm/nvsentinel -n nvsentinel -f deployments/helm/values-sidecar-test.yaml

image:
  repository: ttl.sh/device-api-server-sidecar
  tag: "2h"
  pullPolicy: Always

# Disable built-in NVML provider (use sidecar instead)
nvml:
  enabled: false

# Enable NVML Provider sidecar
nvmlProvider:
  enabled: true
  image:
    repository: ttl.sh/nvml-provider-sidecar
    tag: "2h"
    pullPolicy: Always
  serverAddress: "localhost:9001"
  providerID: "nvml-provider-sidecar"
  driverRoot: /run/nvidia/driver
  healthCheckEnabled: true
  healthPort: 8082
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# Override node selector (cluster uses node-type=gpu instead of nvidia.com/gpu.present)
nodeSelector:
  node-type: gpu

# RuntimeClass for NVML access
runtimeClassName: nvidia

logging:
  verbosity: 2
  format: json
