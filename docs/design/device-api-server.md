# Device API Server - Design & Implementation Plan

> **Status**: Draft  
> **Author**: NVSentinel Team  
> **Created**: 2026-01-21  

## Table of Contents

- [Executive Summary](#executive-summary)
- [Architecture Overview](#architecture-overview)
- [Design Decisions](#design-decisions)
- [Implementation Phases](#implementation-phases)
- [Directory Structure](#directory-structure)
- [API Design](#api-design)
- [Observability](#observability)
- [Deployment](#deployment)

## Related Documents

- [Implementation Tasks](./device-api-server-tasks.md) - Detailed task breakdown
- [NVML Fallback Provider](./nvml-fallback-provider.md) - Built-in NVML health provider design

---

## Executive Summary

The Device API Server is a **node-local gRPC cache server** deployed as a Kubernetes DaemonSet. It acts as an intermediary between:

- **Providers** (e.g., NVSentinel health monitors) that update GPU device states
- **Consumers** (e.g., Device Plugins, DRA Drivers) that read device states for scheduling decisions

### Key Requirements

| Requirement | Description |
|-------------|-------------|
| Node-local | DaemonSet running on each GPU node |
| Read-blocking semantics | MUST block reads during provider updates to prevent stale data |
| Multiple providers | Support multiple health monitors updating different conditions |
| Multiple consumers | Support multiple readers (device-plugin, DRA driver, etc.) |
| Kubernetes patterns | klog/v2, structured logging, health probes |
| Helm-only deployment | No kustomize, pure Helm chart |
| Observability | Prometheus metrics, alerting rules |

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Kubernetes Node                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     NVSentinel       â”‚                     â”‚    Device Plugin / DRA       â”‚  â”‚
â”‚  â”‚   (Health Monitor)   â”‚                     â”‚         Driver               â”‚  â”‚
â”‚  â”‚      [Provider]      â”‚                     â”‚        [Consumer]            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                                                 â”‚                  â”‚
â”‚             â”‚ UpdateGpuStatus()                               â”‚ GetGpu()         â”‚
â”‚             â”‚ (gRPC)                                          â”‚ ListGpus()       â”‚
â”‚             â”‚                                                 â”‚ WatchGpus()      â”‚
â”‚             â–¼                                                 â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        Device API Server (DaemonSet)                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚                         gRPC Server                                 â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                  GpuService (Unified)                      â”‚   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Write: CreateGpu, UpdateGpu, UpdateGpuStatus, DeleteGpu  â”‚   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Read:  GetGpu, ListGpus, WatchGpus                       â”‚   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                    â”‚                               â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                    â–¼                               â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                    Cache Layer                               â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚              sync.RWMutex (Writer-Preference)         â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚                                                       â”‚  â”‚  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   Write Lock() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Blocks ALL new RLock()     â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚                            until write completes      â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚                                                       â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   This ensures consumers NEVER read stale data when   â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   a provider is updating (healthy â†’ unhealthy)        â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                              â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚              map[string]*Gpu (In-Memory Store)        â”‚  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                    Watch Broadcaster                         â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  Notifies all WatchGpus() streams on state changes          â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ Health      â”‚  â”‚ Metrics     â”‚  â”‚ Unix Socket                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ :8081       â”‚  â”‚ :9090       â”‚  â”‚ /var/run/device-api/device.sock â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ /healthz    â”‚  â”‚ /metrics    â”‚  â”‚ (node-local gRPC)               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ /readyz     â”‚  â”‚             â”‚  â”‚                                 â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow: Read-Blocking Semantics

```
Timeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º

Provider (NVSentinel)           Cache (RWMutex)              Consumer (Device Plugin)
        â”‚                              â”‚                              â”‚
        â”‚                              â”‚â—„â”€â”€â”€â”€ RLock() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ GetGpu()
        â”‚                              â”‚      (allowed)               â”‚
        â”‚                              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Returns data
        â”‚                              â”‚      RUnlock()               â”‚
        â”‚                              â”‚                              â”‚
        â”‚â”€â”€â”€â”€ UpdateGpuStatus() â”€â”€â”€â”€â”€â”€â–ºâ”‚                              â”‚
        â”‚     Lock() requested         â”‚                              â”‚
        â”‚                              â”‚                              â”‚
        â”‚                              â”‚â—„â”€â”€â”€â”€ RLock() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ GetGpu()
        â”‚                              â”‚      BLOCKED â›”               â”‚ (waits)
        â”‚                              â”‚                              â”‚
        â”‚â—„â”€â”€â”€â”€ Lock() acquired â”€â”€â”€â”€â”€â”€â”€â”€â”‚                              â”‚
        â”‚      (write in progress)     â”‚                              â”‚
        â”‚                              â”‚                              â”‚
        â”‚â”€â”€â”€â”€ Update complete â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                              â”‚
        â”‚      Unlock()                â”‚                              â”‚
        â”‚                              â”‚                              â”‚
        â”‚                              â”‚â”€â”€â”€â”€ RLock() allowed â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
        â”‚                              â”‚     (fresh data)             â”‚
        â”‚                              â”‚                              â”‚

âš ï¸  CRITICAL: Consumer NEVER reads stale "healthy" state when provider
    is updating to "unhealthy". The RWMutex writer-preference ensures
    new readers block once a write is pending.
```

---

## Design Decisions

### D1: Read-Blocking vs Eventually Consistent

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **sync.RWMutex (writer-preference)** | Prevents stale reads; simple; Go-native | Readers blocked during writes | âœ… **Selected** |
| atomic.Value + copy-on-write | Never blocks readers | Readers may see stale data during update | âŒ Rejected |
| sync.Map | Good for read-heavy | No blocking semantics; may read stale | âŒ Rejected |

**Rationale**: The requirement explicitly states "MUST block reads, preventing false positives when a node 'was' healthy, and the next state is unhealthy." This mandates write-blocking reads.

### D2: Transport Protocol

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **Unix Socket** | Node-local only; no network exposure; fast | Pod must mount socket path | âœ… **Primary** |
| TCP localhost | Easy client setup | Requires port allocation | âœ… **Secondary** |
| hostNetwork + TCP | Accessible from host | Security risk | âŒ Rejected |

**Rationale**: Unix socket provides security isolation and performance for node-local communication. TCP fallback for flexibility.

### D3: Provider Registration Model

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **Implicit (any caller can update)** | Simple; stateless server | No provider identity tracking | âœ… **Phase 1** |
| Explicit registration | Track providers; detect failures | More complexity | ğŸ”® **Phase 2** |

### D4: Logging Framework

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **klog/v2** | Kubernetes native; contextual logging; JSON format | Slightly verbose API | âœ… **Selected** |
| zap | Fast; popular | Not Kubernetes native | âŒ Rejected |
| logr | Interface-based | Needs backend anyway | Used via klog |

---

## Implementation Phases

### Phase 1: Core Server Foundation

**Goal**: Minimal viable gRPC server with cache and blocking semantics.

| Task ID | Task | Description | Estimate |
|---------|------|-------------|----------|
| P1.1 | Project scaffolding | Create `cmd/device-api-server/`, `internal/` structure | S |
| P1.2 | Proto extensions | Add provider-side RPCs (UpdateGpuStatus, RegisterGpu, UnregisterGpu) | M |
| P1.3 | Cache implementation | Thread-safe cache with RWMutex, writer-preference blocking | M |
| P1.4 | Consumer gRPC service | Implement GetGpu, ListGpus, WatchGpus (read path) | M |
| P1.5 | Provider gRPC service | Implement UpdateGpuStatus, RegisterGpu, UnregisterGpu (write path) | M |
| P1.6 | Watch broadcaster | Fan-out changes to all active WatchGpus streams | M |
| P1.7 | Graceful shutdown | SIGTERM handling, drain connections, health status | S |
| P1.8 | Unit tests | Cache tests, service tests, blocking behavior tests | L |

**Deliverables**:
- Working gRPC server binary
- Consumer and Provider services
- Basic health endpoint

---

### Phase 2: Kubernetes Integration

**Goal**: Production-ready DaemonSet with proper k8s integration.

| Task ID | Task | Description | Estimate |
|---------|------|-------------|----------|
| P2.1 | klog/v2 integration | Structured logging, contextual loggers, log levels | M |
| P2.2 | Health probes | gRPC health protocol, HTTP /healthz /readyz endpoints | M |
| P2.3 | Configuration | Flags, environment variables, config validation | S |
| P2.4 | Unix socket support | Listen on configurable socket path | S |
| P2.5 | Signal handling | Proper SIGTERM/SIGINT handling per k8s lifecycle | S |
| P2.6 | Integration tests | Test with mock providers/consumers | L |

**Deliverables**:
- Kubernetes-ready binary
- Health endpoints
- Configurable via flags/env

---

### Phase 3: Observability

**Goal**: Full observability stack with metrics and alerts.

| Task ID | Task | Description | Estimate |
|---------|------|-------------|----------|
| P3.1 | Prometheus metrics | Request counts, latencies, cache stats, connection counts | M |
| P3.2 | gRPC interceptors | grpc-prometheus interceptors for all RPCs | M |
| P3.3 | Custom metrics | `device_api_server_gpus_total`, `_unhealthy`, `_cache_*` | M |
| P3.4 | Metrics endpoint | HTTP /metrics on separate port | S |
| P3.5 | Alerting rules | PrometheusRule CRD for critical alerts | M |
| P3.6 | Grafana dashboard | JSON dashboard for visualization | M |

**Metrics to implement**:

```
# Server metrics
device_api_server_info{version="...", go_version="..."}
device_api_server_up

# Cache metrics  
device_api_server_cache_gpus_total
device_api_server_cache_gpus_healthy
device_api_server_cache_gpus_unhealthy
device_api_server_cache_updates_total{provider="..."}
device_api_server_cache_lock_wait_seconds_bucket

# gRPC metrics (via interceptor)
grpc_server_started_total{grpc_service, grpc_method}
grpc_server_handled_total{grpc_service, grpc_method, grpc_code}
grpc_server_handling_seconds_bucket{grpc_service, grpc_method}

# Watch metrics
device_api_server_watch_streams_active
device_api_server_watch_events_total{type="ADDED|MODIFIED|DELETED"}
```

**Alerts**:

```yaml
- alert: DeviceAPIServerDown
  expr: up{job="device-api-server"} == 0
  for: 5m
  
- alert: DeviceAPIServerHighLatency  
  expr: histogram_quantile(0.99, grpc_server_handling_seconds_bucket) > 0.5
  for: 5m
  
- alert: DeviceAPIServerUnhealthyGPUs
  expr: device_api_server_cache_gpus_unhealthy > 0
  for: 1m
```

---

### Phase 4: Helm Chart

**Goal**: Production-ready Helm chart with all configurations.

| Task ID | Task | Description | Estimate |
|---------|------|-------------|----------|
| P4.1 | Chart scaffolding | `charts/device-api-server/` structure | S |
| P4.2 | DaemonSet template | Node selector, tolerations, resource limits | M |
| P4.3 | RBAC templates | ServiceAccount, Role, RoleBinding | M |
| P4.4 | ConfigMap/Secret | Server configuration, TLS certs | M |
| P4.5 | Service templates | Headless service, metrics service | S |
| P4.6 | PrometheusRule | Alerting rules as k8s resource | M |
| P4.7 | ServiceMonitor | Prometheus scrape configuration | S |
| P4.8 | Values schema | JSON schema for values validation | M |
| P4.9 | Chart tests | Helm test hooks | M |
| P4.10 | Documentation | README, NOTES.txt, examples | M |

**Chart Structure**:

```
charts/device-api-server/
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ values.yaml
â”œâ”€â”€ values.schema.json
â”œâ”€â”€ README.md
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ _helpers.tpl
â”‚   â”œâ”€â”€ daemonset.yaml
â”‚   â”œâ”€â”€ serviceaccount.yaml
â”‚   â”œâ”€â”€ role.yaml
â”‚   â”œâ”€â”€ rolebinding.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ service-metrics.yaml
â”‚   â”œâ”€â”€ servicemonitor.yaml
â”‚   â”œâ”€â”€ prometheusrule.yaml
â”‚   â”œâ”€â”€ poddisruptionbudget.yaml
â”‚   â””â”€â”€ NOTES.txt
â””â”€â”€ tests/
    â””â”€â”€ test-connection.yaml
```

---

### Phase 5: Documentation & Polish

**Goal**: Comprehensive documentation and production hardening.

| Task ID | Task | Description | Estimate |
|---------|------|-------------|----------|
| P5.1 | Architecture docs | Design document, diagrams | M |
| P5.2 | API reference | Proto documentation, examples | M |
| P5.3 | Operations guide | Deployment, troubleshooting, runbooks | L |
| P5.4 | Developer guide | Contributing, local development | M |
| P5.5 | Security hardening | TLS, authentication review | M |
| P5.6 | Performance testing | Benchmark under load | L |
| P5.7 | CI/CD pipeline | GitHub Actions for build, test, release | M |

---

## Directory Structure

Following the [kubernetes-sigs/node-feature-discovery](https://github.com/kubernetes-sigs/node-feature-discovery) pattern
where the `api/` is a standalone module and `pkg/` contains public library code:

```
NVSentinel/
â”œâ”€â”€ api/                                   # STANDALONE API MODULE (own go.mod)
â”‚   â”œâ”€â”€ gen/go/device/v1alpha1/            # Generated Go code
â”‚   â”‚   â”œâ”€â”€ gpu.pb.go
â”‚   â”‚   â””â”€â”€ gpu_grpc.pb.go
â”‚   â”œâ”€â”€ proto/device/v1alpha1/             # Proto definitions
â”‚   â”‚   â””â”€â”€ gpu.proto                      # Unified GpuService (CRUD operations)
â”‚   â”œâ”€â”€ go.mod                             # module github.com/nvidia/nvsentinel/api
â”‚   â”œâ”€â”€ go.sum
â”‚   â””â”€â”€ Makefile
â”œâ”€â”€ cmd/                                   # Command entry points (thin)
â”‚   â””â”€â”€ device-api-server/
â”‚       â””â”€â”€ main.go                        # Server entrypoint only
â”œâ”€â”€ pkg/                                   # PUBLIC LIBRARY CODE (importable)
â”‚   â”œâ”€â”€ deviceapiserver/                   # Device API Server implementation
â”‚   â”‚   â”œâ”€â”€ cache/                         # Thread-safe GPU cache
â”‚   â”‚   â”‚   â”œâ”€â”€ cache.go
â”‚   â”‚   â”‚   â”œâ”€â”€ cache_test.go
â”‚   â”‚   â”‚   â””â”€â”€ broadcaster.go
â”‚   â”‚   â”œâ”€â”€ service/                       # gRPC service implementation
â”‚   â”‚   â”‚   â””â”€â”€ gpu_service.go             # GpuService (unified read/write)
â”‚   â”‚   â”œâ”€â”€ nvml/                          # NVML provider (uses gRPC client)
â”‚   â”‚   â”‚   â”œâ”€â”€ provider.go
â”‚   â”‚   â”‚   â”œâ”€â”€ enumerator.go
â”‚   â”‚   â”‚   â””â”€â”€ health_monitor.go
â”‚   â”‚   â”œâ”€â”€ metrics/                       # Prometheus metrics
â”‚   â”‚   â””â”€â”€ health/                        # Health check handlers
â”‚   â”œâ”€â”€ version/                           # Version information
â”‚   â”‚   â””â”€â”€ version.go
â”‚   â””â”€â”€ signals/                           # Signal handling utilities
â”œâ”€â”€ charts/                                # Helm charts
â”‚   â””â”€â”€ device-api-server/
â”‚       â”œâ”€â”€ Chart.yaml
â”‚       â”œâ”€â”€ values.yaml
â”‚       â””â”€â”€ templates/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ design/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ operations/
â”œâ”€â”€ hack/                                  # Build/development scripts
â”œâ”€â”€ test/                                  # E2E tests
â”œâ”€â”€ go.mod                                 # Root module with replace directive
â”œâ”€â”€ go.sum
â””â”€â”€ Makefile
```

**Key Layout Decisions:**

| Directory | Purpose | Importable |
|-----------|---------|------------|
| `api/` | Standalone API module for versioning | Yes (own module) |
| `pkg/` | Public library code | Yes |
| `cmd/` | Thin entry points | No |
| `charts/` | Helm deployment | N/A |

Root `go.mod` uses: `replace github.com/nvidia/nvsentinel/api => ./api`

---

## API Design

### Unified GpuService

Following Kubernetes API conventions, the API is consolidated into a single `GpuService` with standard CRUD methods:

```protobuf
// GpuService provides a unified API for managing GPU resources.
//
// Read operations (Get, List, Watch) are intended for consumers.
// Write operations (Create, Update, UpdateStatus, Delete) are intended for providers.
service GpuService {
  // Read Operations
  rpc GetGpu(GetGpuRequest) returns (Gpu);
  rpc ListGpus(ListGpusRequest) returns (ListGpusResponse);
  rpc WatchGpus(WatchGpusRequest) returns (stream WatchGpusResponse);

  // Write Operations
  rpc CreateGpu(CreateGpuRequest) returns (CreateGpuResponse);
  rpc UpdateGpu(UpdateGpuRequest) returns (Gpu);
  rpc UpdateGpuStatus(UpdateGpuStatusRequest) returns (Gpu);
  rpc DeleteGpu(DeleteGpuRequest) returns (google.protobuf.Empty);
}

message CreateGpuRequest {
  Gpu gpu = 1;  // metadata.name and spec.uuid required
}

message CreateGpuResponse {
  Gpu gpu = 1;
  bool created = 2;  // true if new, false if already existed
}

message UpdateGpuRequest {
  Gpu gpu = 1;  // includes resource_version for optimistic concurrency
}

message UpdateGpuStatusRequest {
  string name = 1;
  GpuStatus status = 2;
  int64 resource_version = 3;  // optional, for conflict detection
}

message DeleteGpuRequest {
  string name = 1;
}
```

**Design Rationale**:
- Single service simplifies API surface and tooling compatibility
- Standard CRUD verbs enable better integration with Kubernetes patterns
- `UpdateGpuStatus` follows the Kubernetes subresource pattern
- Optimistic concurrency via `resource_version` prevents lost updates

---

## Observability

### Metrics Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Device API Server                             â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   gRPC Interceptors                      â”‚    â”‚
â”‚  â”‚  grpc_server_started_total                               â”‚    â”‚
â”‚  â”‚  grpc_server_handled_total                               â”‚    â”‚
â”‚  â”‚  grpc_server_handling_seconds_bucket                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   Custom Metrics                         â”‚    â”‚
â”‚  â”‚  device_api_server_cache_gpus_total                      â”‚    â”‚
â”‚  â”‚  device_api_server_cache_lock_contention_total           â”‚    â”‚
â”‚  â”‚  device_api_server_watch_streams_active                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   Go Runtime Metrics                     â”‚    â”‚
â”‚  â”‚  go_goroutines                                           â”‚    â”‚
â”‚  â”‚  go_memstats_alloc_bytes                                 â”‚    â”‚
â”‚  â”‚  process_cpu_seconds_total                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚                    :9090/metrics                                 â”‚
â”‚                              â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Prometheus                                 â”‚
â”‚                                                                  â”‚
â”‚  ServiceMonitor â”€â”€â–º scrape_configs                               â”‚
â”‚                                                                  â”‚
â”‚  PrometheusRule â”€â”€â–º alerting_rules                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Grafana                                   â”‚
â”‚                                                                  â”‚
â”‚  Dashboard: Device API Server Overview                           â”‚
â”‚  - Request rate / error rate                                     â”‚
â”‚  - P50/P99 latency                                               â”‚
â”‚  - GPU health summary                                            â”‚
â”‚  - Cache statistics                                              â”‚
â”‚  - Active watch streams                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Deployment

### Helm Values (Key Configuration)

```yaml
# values.yaml
replicaCount: 1  # DaemonSet ignores this, but kept for consistency

image:
  repository: ghcr.io/nvidia/device-api-server
  tag: ""  # Defaults to Chart appVersion
  pullPolicy: IfNotPresent

# Server configuration
server:
  # gRPC listen address (TCP) - localhost only by default for security
  # Set to ":50051" to bind to all interfaces (WARNING: unauthenticated API)
  grpcAddress: "127.0.0.1:50051"
  # Unix socket path (primary for node-local)
  unixSocket: /var/run/device-api/device.sock
  # Health probe port
  healthPort: 8081
  # Metrics port
  metricsPort: 9090

# Logging
logging:
  # Log level (0=info, higher=more verbose)
  verbosity: 0
  # Output format: text, json
  format: json

# Node selection
nodeSelector:
  nvidia.com/gpu.present: "true"

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

resources:
  requests:
    cpu: 50m
    memory: 64Mi
  limits:
    cpu: 200m
    memory: 256Mi

# Security
securityContext:
  runAsNonRoot: true
  runAsUser: 65534
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false

# RBAC
serviceAccount:
  create: true
  name: ""
  automountServiceAccountToken: false

rbac:
  create: true

# Observability
metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    scrapeTimeout: 10s
  prometheusRule:
    enabled: true

# Health probes
probes:
  liveness:
    initialDelaySeconds: 5
    periodSeconds: 10
  readiness:
    initialDelaySeconds: 5
    periodSeconds: 10
```

### DaemonSet Topology

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Kubernetes Cluster                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚      GPU Node 1       â”‚  â”‚      GPU Node 2       â”‚  â”‚      GPU Node 3       â”‚â”‚
â”‚  â”‚                       â”‚  â”‚                       â”‚  â”‚                       â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚  â”‚  â”‚ device-api-     â”‚  â”‚  â”‚  â”‚ device-api-     â”‚  â”‚  â”‚  â”‚ device-api-     â”‚  â”‚â”‚
â”‚  â”‚  â”‚ server pod      â”‚  â”‚  â”‚  â”‚ server pod      â”‚  â”‚  â”‚  â”‚ server pod      â”‚  â”‚â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚  â”‚  â”‚                 â”‚  â”‚  â”‚  â”‚                 â”‚  â”‚â”‚
â”‚  â”‚  â”‚ GPU-0: Healthy  â”‚  â”‚  â”‚  â”‚ GPU-0: Healthy  â”‚  â”‚  â”‚  â”‚ GPU-0: Unhealthyâ”‚  â”‚â”‚
â”‚  â”‚  â”‚ GPU-1: Healthy  â”‚  â”‚  â”‚  â”‚ GPU-1: Healthy  â”‚  â”‚  â”‚  â”‚ GPU-1: Healthy  â”‚  â”‚â”‚
â”‚  â”‚  â”‚ GPU-2: Healthy  â”‚  â”‚  â”‚  â”‚                 â”‚  â”‚  â”‚  â”‚ GPU-2: Healthy  â”‚  â”‚â”‚
â”‚  â”‚  â”‚ GPU-3: Healthy  â”‚  â”‚  â”‚  â”‚                 â”‚  â”‚  â”‚  â”‚ GPU-3: Healthy  â”‚  â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚  â”‚                       â”‚  â”‚                       â”‚  â”‚                       â”‚â”‚
â”‚  â”‚  /var/run/device-api/ â”‚  â”‚  /var/run/device-api/ â”‚  â”‚  /var/run/device-api/ â”‚â”‚
â”‚  â”‚    device.sock        â”‚  â”‚    device.sock        â”‚  â”‚    device.sock        â”‚â”‚
â”‚  â”‚                       â”‚  â”‚                       â”‚  â”‚                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚   Non-GPU Node        â”‚  (DaemonSet does NOT schedule here due to            â”‚
â”‚  â”‚   (No GPU)            â”‚   nodeSelector: nvidia.com/gpu.present=true)         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Risk Assessment

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Cache corruption on concurrent writes | High | Low | RWMutex provides exclusivity |
| Watch stream memory leak | Medium | Medium | Bounded channels, timeouts |
| Provider not updating (stale data) | High | Medium | Health checks, provider heartbeat (Phase 2) |
| Socket permission issues | Medium | Medium | Init container for socket dir |
| High lock contention | Medium | Low | Metrics to detect, sharding if needed |

---

## Success Criteria

### Phase 1
- [ ] Server starts and accepts gRPC connections
- [ ] Provider can register/update/unregister GPUs
- [ ] Consumer can Get/List/Watch GPUs
- [ ] Read-blocking verified under concurrent load

### Phase 2
- [ ] Structured logs with klog/v2
- [ ] Health probes pass in Kubernetes
- [ ] Unix socket communication works

### Phase 3
- [ ] Prometheus metrics exposed
- [ ] Grafana dashboard visualizes key metrics
- [ ] Alerts fire correctly in test scenarios

### Phase 4
- [ ] `helm install` works out of box
- [ ] DaemonSet schedules on GPU nodes only
- [ ] RBAC properly scoped

### Phase 5
- [ ] Documentation complete
- [ ] CI/CD pipeline green
- [ ] Performance benchmarks pass

---

## Appendix: Research References

1. **Kubernetes DaemonSet gRPC Best Practices** - Health probes, graceful shutdown, load balancing
2. **Go sync.RWMutex** - Writer-preference semantics, blocking behavior
3. **klog/v2** - Structured logging, contextual logging, JSON format
4. **Helm Chart Best Practices** - RBAC, ServiceAccount, DaemonSet templates
5. **grpc-prometheus** - Metrics interceptors, histogram configuration

---

*Document version: 1.0*  
*Last updated: 2026-01-21*
